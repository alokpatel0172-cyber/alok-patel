<img width="269" height="148" alt="image" src="https://github.com/user-attachments/assets/d1c84117-c86d-46e0-97af-e6b04dce0c55" />

Car Price Prediction using Linear Regression Models
 Objective

The objective of this project is to implement and compare different Linear Regression models including Simple Linear Regression, Multiple Linear Regression, Polynomial Regression, Ridge Regression, and Lasso Regression using a car price dataset.

Dataset

The dataset used in this project is the Car Price Dataset.
It contains various car features such as engine size, mileage, year, horsepower, and price.

Dataset Type: CSV
Target Variable: Price
Input Features: Engine Size, Mileage, Year, etc.

ðŸ›  Tools and Technologies

Python

Google Colab

Pandas

NumPy

Matplotlib

Seaborn

Scikit-Learn

 Methodology
 1. Exploratory Data Analysis (EDA)

Checked dataset structure

Checked missing values

Generated statistical summary

Plotted feature distribution graphs

Created correlation heatmap

 2. Simple Linear Regression

Used Engine Size as single input feature

Built regression model

Plotted regression line

 3. Multiple Linear Regression

Used multiple features like engine size, mileage, year

Trained regression model

Evaluated performance using MSE, RMSE, and RÂ²

 4. Polynomial Regression

Applied Polynomial Features (degree = 2)

Captured non-linear relationships

Compared performance with linear regression

 5. Regularization Techniques
Ridge Regression

Reduced overfitting

Reduced coefficient values

Lasso Regression

Performed feature selection

Reduced some coefficients to zero
 6. Model Diagnostics

Residual Plot created

Checked regression assumptions

 Evaluation Metrics

Mean Squared Error (MSE)

Root Mean Squared Error (RMSE)

RÂ² Score

Results

Multiple Linear Regression performed better than Simple Linear Regression.

Polynomial Regression captured non-linear relationships and improved accuracy.

Ridge Regression reduced overfitting.

Lasso Regression helped identify important features.

 Conclusion

This project helped in understanding different regression models and their performance.
Polynomial regression improved prediction accuracy by capturing non-linear patterns.
Regularization techniques helped improve model stability and feature selection.

 Files Included

Jupyter Notebook (.ipynb)

Dataset (.csv)

Output Graphs

Author

Student Name: ALOK PATEL
Course: Machine Learning Lab
Submission: Assignment 1
